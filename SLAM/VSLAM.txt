"世界坐标 ---> 相机坐标 ---> 相机归一化坐标 ---> 像素坐标"

# 【群论--用于位姿优化】

李群：SO(3)---旋转矩阵、SE(3)---变换矩阵；
李代数是李群表示的曲面空间的正切空间（群求导-->代数）；
旋转矩阵R的微分 = 一个反对称矩阵*R自身，若该旋转矩阵--->李群，则该反对称矩阵--->该李群对应的李代数；
该反对称矩阵取e的指数，pow(e, 该反对称矩阵) = R，也即是下面的指数映射；
代数-->李群：指数映射（也就是罗格里斯公式）；
李群-->代数：对数映射；
群与代数关系：在[-pai,pai]是一一对应的；
李群只对乘法封闭，而李代数对加法封闭（因此需要作加法时，转换到李代数上做）；

# 【非线性优化】

Ceres、g2o：都是求解最小二乘，Ceres：谷歌库，具有自动求导机制、资料多，g2o：基于图优化、资料少；
超定方程求最小二乘解；

非线性优化推导过程：输入u，观测z，估计状态x ---> 条件概率P(x|z,u) ---(贝叶斯)--> P(x|Z)=P(Z|x)*P(x)/P(Z)(后验=似然*先验) ---(要求后验最大化，似然就得最大化，变为作最大似然估计)--> 对运动方程/观测方程作高斯分布，取其负对数分析 ---> 误差的二范数最小问题(非线性最小二乘问题) ---> 求解方法(1-极值点，2-梯度下降)；
梯度下降：在函数求导复杂时(不好解出极值点)，寻找一个带方向的增量，直到增量很小时，使目标函数达到一个极小；
1阶梯度法：泰勒展开保留1阶项（最速下降法）
2阶梯度法：泰勒展开保留2阶项（牛顿法）：高斯牛顿法、列文伯格-马夸尔特法(阻尼牛顿法，增加了每次梯度的约束信赖区域)
雅克比矩阵J：矩阵的一阶导
海塞矩阵H：矩阵的二阶导

# 【视觉里程计OV-前端】

1、ORB完成特征点匹配：求FAST关键点（角点）keypoints_1 ---> 求BRIEF描述子descriptors_1 ---> 使用描述子进行两帧间匹配matches
（角点：一般为极值点，是性质突出的点；角点选取：设置阈值，与邻域圆上的像素点进行比较；可以适应平移、旋转、缩放）；

2、位姿估计：（就是基于上述特征点匹配，求解变换矩阵）
对极几何（2D2D）：a.求E本质矩阵(采用8点法) ---> 进行分解得到4组R,t ---> 用深度为正(点在相机前方)筛选出正确解（基本矩阵F可以由E与相机内参矩阵K运算得到），缺点：纯旋转问题无法求解；
		 b.求H单应矩阵 ---> 进行分解得到多组R,t ---> 用深度为正、场景与相机平行(存在法向量)筛选出正确解（特征点处于同一平面上时可用此方法）；
一般测试深度为正，采用三角化检测角点的方法；
单目slam初始化时运动必须要有平移（解决尺度的不确定性）；

PnP（3D2D）：DLT（直接线性变换，需要6对点）、P3P（需要世界坐标系3对3D-2D点的三角关系，需要深度信息）、BA估值调整（g2o的图优化）；构建3D2D重投影误差并最小化；

ICP（3D3D）：(3D-3D点计算位姿,构建3D3D误差并最小化)
过程：计算两幅图各自3d点的均值-->求偏移量-->计算q1*q2^T-->SVD分解-->求R、t；

3、直接法位姿估计（相比于特征点法只能构建稀疏地图，此方法可以构建稠密地图，需要在场景存在明暗变化）
光流：追踪特征追踪，而不含位姿估计，后续估计可采用上述方法进行（计算关键点(角点)进行追踪，要求相机运动较慢）；
直接法：根据当前相机的位姿估计值寻找另一帧的匹配点（使用前需要以细致的光度模型标定相机）

# 【后端】（基于KF系列滤波-线性 或者 图优化-非线性）

后端主要以非线性优化为主；

KF：假设马尔可夫性(当前状态至于只与上一时刻状态相关)，即使是扩展卡尔曼每次在运算时也是在工作点作了一次线性化，偏离工作点较远时，仍存在较大误差；

Bundle Adjustment：相机位姿与空间点的图优化为BA，过程：构建代价函数(总体误差函数，以二范数平方和评估)，使用Schur消元稀疏化加速计算，使用高斯牛顿/列文伯格求解增量方程，对位姿和路标进行调整；由于误差量化的时候，二范数增长过快，若出现错误数据，导致误差很大，故引入鲁棒核函数替换二范数度量(Huber核函数等)；

位姿图(Pose)：由于BA及时使用稀疏性，随时间增长效率也会下降，解决办法：1-滑动窗口丢掉历史数据，2-使用位姿图(只优化相机位姿，不再优化路标点)；

# 【回环检测】（检测间隔远的帧判断相机运动是否经过该位置）

词袋模型BoW：根据两幅图像上有哪几种特征，构成单词-字典模型；
一幅图像的特征集合称为字典 A = 哪几种特征称为单词 1*w1 + 1*w2 + 0*w3...，wx前的系数为1、0，构成描述字典的向量，两幅图像的向量取1阶范数得到图像的相似性；单词从特征点的聚类得到（K-means）；字典存储采用k-d树（每个节点分支k个，深度d，容纳pow(k,d)单词）
过程：寻找特征点 ---> 聚类Clustering ---> 存储字典 ---> 进行相似度评估(利用图像的特征点与字典进行对比，返回相似性scores) 
DBoW3有两个主要的类：Vocabulary 和 Database；
效果不太好时，考虑训练字典增大；（词袋模型的检测未来可能被CNN干掉）；























